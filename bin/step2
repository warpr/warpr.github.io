#!/usr/bin/env python2
# -*- mode: python, encoding: utf-8 -*-

from __future__ import absolute_import
from __future__ import print_function
from __future__ import unicode_literals

# requirements:
# sudo apt-get install python-html5lib python-lxml python-iso8601 python-tz

import os
import codecs
import datetime
import iso8601
import itertools
import json
import lxml.html
import pytz
import re
import requests
from collections import namedtuple
from os.path import abspath, dirname, isdir, isfile, join

Activity = namedtuple(
    "Activity", "avatar title summary url datetime type level service")

_root = dirname (dirname (abspath (__file__)))

def parse_html (filename):
    with codecs.open (filename, "rb", "UTF-8") as f:
        return lxml.html.fromstring (f.read ().encode ("UTF-8"))


def parse_xml (filename):
    with codecs.open (filename, "rb", "UTF-8") as f:
        return lxml.etree.parse (f)


def parse_json (filename):
    with codecs.open (filename, "rb", "UTF-8") as f:
        return json.loads (f.read ())


def fix_links (base_uri, dom):
    for a in dom.cssselect ('a'):
        if 'href' not in a.attrib:
            continue

        if a.attrib['href'].startswith ('/'):
            a.attrib['href'] = base_uri + a.attrib['href']


def trim_whitespace (dom):
    ws = re.compile (r'\W+')

    for elem in dom.iter ('*'):
        if elem.text is not None:
            elem.text = ws.sub (' ', elem.text)
        if elem.tail is not None:
            elem.tail = ws.sub (' ', elem.tail)


def prune_class (css_class, skip):
    classes = css_class.split (' ')
    for cls in classes:
        if cls not in skip:
            return cls
    return None


def tweet_timestamp (url):
    print ("Getting timestamp for tweet", url)

    response = requests.get ('https://twitter.com' + url)
    dom = lxml.html.fromstring (response.content)

    span = dom.cssselect ('span[data-time]')[0]
    timestamp = int(span.attrib['data-time'])
    # timestamp = 1383215546
    dt = datetime.datetime.utcfromtimestamp(timestamp)
    return dt.replace (tzinfo=pytz.utc)


def twitter (filename):
    base_uri = 'https://twitter.com'

    dom = parse_html (filename)
    fix_links (base_uri, dom)

    for tweet in dom.cssselect ('table.tweet')[0:5]:
        tweet_content = tweet.cssselect ('.tweet-text')[0]
        tweet_context = tweet.cssselect ('.tweet-social-context span.context')
        retweet = True if tweet_context else False

        title = tweet_context[0].text if retweet else None

        yield Activity(
            avatar=tweet.cssselect ('.avatar img')[0].attrib['src'],
            title=title,
            url=base_uri + tweet.attrib['href'],
            summary=lxml.html.tostring (tweet_content),
            datetime=tweet_timestamp (tweet.attrib['href']),
            level="minor" if retweet else "major",
            type="tweet",
            service="twitter")


def bitbucket (filename):
    base_uri = 'https://bitbucket.org'

    dom = parse_html (filename)
    fix_links (base_uri, dom)

    for article in dom.cssselect ('article.news-item'):
        desc = article.cssselect ('p')[0]
        trim_whitespace (desc)

        changeset = article.cssselect('div.changeset a')
        url = changeset[0].attrib['href'] if changeset else None

        dt = iso8601.parse_date (article.cssselect ('time')[0].attrib['datetime'])

        yield Activity(
            avatar=article.cssselect ('img.avatar')[0].attrib['src'],
            title=None,
            url=url,
            summary=lxml.html.tostring (desc),
            datetime=dt,
            level="minor",
            type=prune_class (article.attrib['class'], [ 'news-item' ]),
            service="bitbucket")


def github_actor (event):
    return '<a href="%s">%s</a>' % (
        'https://github.com/' + event["actor"]["login"],
        event["actor"]["login"])

def github_fix_repo_url (url):
    return url.replace ('https://api.github.com/repos/',
                        'https://github.com/')

def github_issue_comment_event (event):
    summary = ('%s commented on <a href="%s">%s</a> ' +
               '<a href="%s">issue #%s</a>.') % (
                   github_actor (event),
                   github_fix_repo_url (event["repo"]["url"]),
                   event["repo"]["name"],
                   event["payload"]["issue"]["html_url"],
                   event["payload"]["issue"]["number"])

    return (event["payload"]["issue"]["html_url"], summary)


def github_push_event (event):
    topic = "a commit"
    if event["payload"]["size"] > 1:
        topic = unicode(event["payload"]["size"]) + " commits"

    commit_url = github_fix_repo_url (event["payload"]["commits"][0]["url"])

    summary = ('%s pushed <a href="%s">%s</a> to <a href="%s">%s</a>.') % (
        github_actor (event),
        commit_url,
        topic,
        github_fix_repo_url (event["repo"]["url"]),
        event["repo"]["name"])

    return (commit_url, summary)


def github_pull_request_event (event):
    pull_request_url = github_fix_repo_url (
        event["payload"]["pull_request"]["url"])
    summary = ('%s submitted ' +
               '<a href="%s">pull request #%s</a> to <a href="%s">%s</a>.') % (
                   github_actor (event),
                   pull_request_url,
                   event["payload"]["pull_request"]["number"],
                   github_fix_repo_url (event["repo"]["url"]),
                   event["repo"]["name"])

    return (pull_request_url, summary)


def github_create_event (event):
    summary = ('%s created %s %s in <a href="%s">%s</a>.') % (
        github_actor (event),
        event["payload"]["ref_type"],
        event["payload"]["ref"],
        github_fix_repo_url (event["repo"]["url"]),
        event["repo"]["name"])

    return (github_fix_repo_url (event["repo"]["url"]), summary)


def github (filename):
    data = parse_json (filename)

    activity = {}
    activity["PushEvent"] = github_push_event
    activity["IssueCommentEvent"] = github_issue_comment_event
    activity["PullRequestEvent"] = github_pull_request_event
    activity["CreateEvent"] = github_create_event

    level = {}
    level["PushEvent"] = "minor"
    level["IssueCommentEvent"] = "minor"
    level["PullRequestEvent"] = "minor"
    level["CreateEvent"] = "minor"

    for event in data:
        if event["type"] not in activity:
            continue

        (url, summary) = activity[event["type"]](event)

        yield Activity(
            avatar=event["actor"]["avatar_url"],
            title=None,
            summary=summary,
            url=url,
            type=event["type"],
            level=level[event["type"]],
            datetime=iso8601.parse_date (event["created_at"]),
            service="github")


def steam (filename):
    data = parse_json (filename)

    user = '<a href="http://steamcommunity.com/id/paksangsoo/">박상수</a>'

    for event in data:
        dt = datetime.datetime.utcfromtimestamp(event["last_played"])
        game = '<a href="http://steamcommunity.com/app/%s">%s</a>' % (
            event["appid"], event["name"])

        yield Activity(
            avatar=None,
            title=None,
            summary=user + ' played ' + game,
            url="http://steamcommunity.com/id/paksangsoo/games/",
            type="played",
            level="minor",
            datetime=dt.replace (tzinfo=pytz.utc),
            service="steam")

def pump (filename):
    data = parse_json (filename)

    for event in data["minor"]["items"]:
        yield Activity(
            avatar=event["actor"]["image"]["url"],
            title=None,
            url=event.get ("url", None),
            summary=event["content"],
            type=event["verb"],
            level="minor",
            datetime=iso8601.parse_date (event["updated"]),
            service="pump.io")

    for event in data["major"]["items"]:
        avatar=event["actor"]["image"]["url"]
        title=None
        title=event["content"]

        if "content" in event.get ("object", {}):
            if "author" in event["object"]:
                avatar=event["object"]["author"]["image"]["url"]
            title=event["content"]
            summary=event["object"]["content"]


        yield Activity(
            avatar=avatar,
            title=title,
            url=event.get ("url", None),
            summary=summary,
            type=event["verb"],
            level="major",
            datetime=iso8601.parse_date (event["updated"]),
            service="pump.io")


def stackoverflow (filename):
    dom = parse_xml (filename)
    ns = { 'atom': 'http://www.w3.org/2005/Atom' }

    for entry in dom.xpath ('//atom:entry', namespaces=ns):
        url = entry.find('atom:link', ns).attrib['href']
        title = entry.find('atom:title', ns).text

        yield Activity(
            avatar=None,
            title=None,
            url=url,
            summary=title,
            datetime=iso8601.parse_date (entry.find('atom:published', ns).text),
            type="post", level="major", service="stackoverflow")


def devblog (filename):
    dom = parse_xml (filename)
    ns = { 'atom': 'http://www.w3.org/2005/Atom' }

    for entry in dom.xpath ('//atom:entry', namespaces=ns):
        url = entry.find('atom:link', ns).attrib['href']
        title = entry.find('atom:title', ns).text
        summary = entry.find('atom:summary', ns).text

        yield Activity(
            avatar=None, title=title, url=url, summary=summary,
            datetime=iso8601.parse_date (entry.find('atom:updated', ns).text),
            type="post", level="major", service="devblog")


def cmp_datetime (a, b):
    return int ((a.datetime - b.datetime).total_seconds ())


def format_timestamp (event):
    event["datetime"] = event["datetime"].isoformat ()
    return event


def write_results (filename, events):
    output = json.dumps ({
        "data": [
            format_timestamp (e._asdict ()) for e in events
        ]}, indent=4)

    print ("Writing to", filename)

    with codecs.open (filename, "wb", "UTF-8") as f:
        f.write (output)


if __name__ == '__main__':
    print ("Parsing events...")

    os.chdir (join (_root, 'activity'))

    events = sorted (itertools.chain (
        bitbucket ("bitbucket.events.html"),
        github ("github.events.json"),
        pump ("identi.ca.json"),
        devblog ("blog.atom.xml"),
        stackoverflow ("stackoverflow.atom.xml"),
        twitter ("twitter.events.html"),
        steam ("steamgames.json")
    ), cmp=cmp_datetime, reverse=True)

    write_results ("events.json", events)

    major = filter (lambda x: x.level == "major", events)
    minor = filter (lambda x: x.level == "minor", events)

    write_results ("minor.json", minor)
    write_results ("major.json", major)
